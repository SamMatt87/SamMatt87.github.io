<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="UTF-8">

<!-- Begin Jekyll SEO tag v2.8.0 -->
<title>CC Fraud | Your awesome title</title>
<meta name="generator" content="Jekyll v3.9.3" />
<meta property="og:title" content="CC Fraud" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="A place to showcase my personal Data Science projects" />
<meta property="og:description" content="A place to showcase my personal Data Science projects" />
<link rel="canonical" href="http://localhost:4000/SciKitLearn-basics/cc-fraud/" />
<meta property="og:url" content="http://localhost:4000/SciKitLearn-basics/cc-fraud/" />
<meta property="og:site_name" content="Your awesome title" />
<meta property="og:type" content="website" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="CC Fraud" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"WebPage","description":"A place to showcase my personal Data Science projects","headline":"CC Fraud","url":"http://localhost:4000/SciKitLearn-basics/cc-fraud/"}</script>
<!-- End Jekyll SEO tag -->

    <link rel="preconnect" href="https://fonts.gstatic.com">
    <link rel="preload" href="https://fonts.googleapis.com/css?family=Open+Sans:400,700&display=swap" as="style" type="text/css" crossorigin>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="theme-color" content="#157878">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <link rel="stylesheet" href="/assets/css/style.css?v=6a77b59639796cfe1ca809921e3586c7a2c64b07">
    <!-- start custom head snippets, customize with your own _includes/head-custom.html file -->

<!-- Setup Google Analytics -->



<!-- You can set your favicon here -->
<!-- link rel="shortcut icon" type="image/x-icon" href="/favicon.ico" -->

<!-- end custom head snippets -->

  </head>
  <body>
    <a id="skip-to-content" href="#content">Skip to the content.</a>

    <header class="page-header" role="banner">
      <h1 class="project-name">CC Fraud</h1>
      <h2 class="project-tagline">A place to showcase my personal Data Science projects</h2>
      
        <a href="https://github.com/SamMatt87/SamMatt87.github.io" class="btn">View on GitHub</a>
      
      
    </header>

    <main id="content" class="main-content" role="main">
      <h2 id="background">Background</h2>
<p>This project used a logistic regression function to pinpoint frauduent credit card transactions. It is important that we look at both the false positive rate and the true positive rate as in a real world scenario, fraudulent transactions only make up a small percentage of all transactions recorded.</p>

<h2 id="the-dataset">The Dataset</h2>
<p>The dataset used for this project can be found on kaggle <a href="https://www.kaggle.com/shubhamjoshi2130of/abstract-data-set-for-credit-card-fraud-detection">here</a>. It includes fields such as the average transaction amount for the card, the amount for this transaction, whether the transaction was declined and whether it was a foreign transaction. You can see a sample of the data below.</p>

<p><img src="https://user-images.githubusercontent.com/18587666/136120239-47379f31-514d-48f5-82be-7006e6d5a8d2.png" alt="image" />
<img src="https://user-images.githubusercontent.com/18587666/136120283-4d914010-e328-40ed-8d81-984bb0bc73d6.png" alt="image" /></p>

<h2 id="the-process">The Process</h2>
<p>The first step of the process was to import some python packages. I imported numpy for running calculatiions, pandas to import the data, pyplot from matplotlib to visualise the model and the logistic regression package from sklearn to build the model. I also imported the data and ran some checks by printing out the top 5 rows and counting the number of merchant ids.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span> 
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span> 
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span> 
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">'creditcardcsvpresent.csv'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">data</span><span class="p">.</span><span class="n">head</span><span class="p">())</span>
<span class="k">print</span><span class="p">(</span><span class="n">data</span><span class="p">.</span><span class="n">Merchant_id</span><span class="p">.</span><span class="n">nunique</span><span class="p">())</span>
</code></pre></div></div>

<p>I then imported train test split to split the data into train and test sets as well as cross val score that outputs the score for each stage of cross validation. I also imported a number of statistical metrics from sklearn including accuracy score, classification report, precision score, recall score, confusion matrix, precision recall curve, roc curve, auc and log loss. I then replaced any no values with 0 and yes values with 1 to binarise the categorical variables.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span><span class="p">,</span> <span class="n">cross_val_score</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span><span class="p">,</span> <span class="n">classification_report</span><span class="p">,</span> <span class="n">precision_score</span><span class="p">,</span> <span class="n">recall_score</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span><span class="p">,</span> <span class="n">precision_recall_curve</span><span class="p">,</span> <span class="n">roc_curve</span><span class="p">,</span> <span class="n">auc</span><span class="p">,</span> <span class="n">log_loss</span>
<span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">.</span><span class="n">replace</span><span class="p">(</span><span class="s">'N'</span><span class="p">,</span><span class="mi">0</span><span class="p">)</span>
<span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">.</span><span class="n">replace</span><span class="p">(</span><span class="s">'Y'</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div></div>

<p>The next steps were to split the data into X and Y variable and create the train and test sets.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">X</span><span class="o">=</span> <span class="n">data</span><span class="p">.</span><span class="n">iloc</span><span class="p">[:,</span><span class="mi">2</span><span class="p">:</span><span class="mi">11</span><span class="p">]</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">data</span><span class="p">[[</span><span class="s">'isFradulent'</span><span class="p">]]</span>

<span class="k">print</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">Y</span><span class="p">.</span><span class="n">head</span><span class="p">())</span>
<span class="n">x_train</span><span class="p">,</span> <span class="n">x_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">Y</span><span class="p">,</span> <span class="n">test_size</span> <span class="o">=</span> <span class="mf">0.2</span><span class="p">)</span>
</code></pre></div></div>

<p>The model was then built on the training set and predictions were run on the test set. the false positive rate, true positive rate and threshold values were then calculated using the roc curve package.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">logreg</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">()</span>
<span class="n">logreg</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">logreg</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span>
<span class="n">y_pred_proba</span> <span class="o">=</span> <span class="n">logreg</span><span class="p">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">x_test</span><span class="p">)[:,</span><span class="mi">1</span><span class="p">]</span>
<span class="p">[</span><span class="n">fpr</span><span class="p">,</span><span class="n">tpr</span><span class="p">,</span><span class="n">thr</span><span class="p">]</span> <span class="o">=</span> <span class="n">roc_curve</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="n">y_pred_proba</span><span class="p">)</span>
</code></pre></div></div>

<p>Using these outputs, I was able to print statements returning the accuracy, log loss and the area under the curve.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="s">'Train/Test split results:'</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="n">logreg</span><span class="p">.</span><span class="n">__class__</span><span class="p">.</span><span class="n">__name__</span><span class="o">+</span><span class="s">" accuracy is %2.3f"</span> <span class="o">%</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="n">logreg</span><span class="p">.</span><span class="n">__class__</span><span class="p">.</span><span class="n">__name__</span><span class="o">+</span><span class="s">" log_loss is %2.3f"</span> <span class="o">%</span> <span class="n">log_loss</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred_proba</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="n">logreg</span><span class="p">.</span><span class="n">__class__</span><span class="p">.</span><span class="n">__name__</span><span class="o">+</span><span class="s">" auc is %2.3f"</span> <span class="o">%</span> <span class="n">auc</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span> <span class="n">tpr</span><span class="p">))</span>
</code></pre></div></div>

<p>Finally, I plotted the ROC graph and found the sensitivity and specificity at the threshold point.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">idx</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nb">min</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">where</span><span class="p">(</span><span class="n">tpr</span> <span class="o">&gt;</span> <span class="mf">0.95</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span><span class="n">tpr</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">'coral'</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="s">'ROC Curve (area=%0.3f)'</span><span class="o">%</span><span class="n">auc</span><span class="p">(</span><span class="n">fpr</span><span class="p">,</span><span class="n">tpr</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">],[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span><span class="s">'k--'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="n">fpr</span><span class="p">[</span><span class="n">idx</span><span class="p">]],[</span><span class="n">tpr</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span><span class="n">tpr</span><span class="p">[</span><span class="n">idx</span><span class="p">]],</span><span class="s">'k--'</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s">'blue'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">plot</span><span class="p">([</span><span class="n">fpr</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span><span class="n">fpr</span><span class="p">[</span><span class="n">idx</span><span class="p">]],[</span><span class="mi">0</span><span class="p">,</span><span class="n">tpr</span><span class="p">[</span><span class="n">idx</span><span class="p">]],</span><span class="s">'k--'</span><span class="p">,</span><span class="n">color</span><span class="o">=</span><span class="s">'blue'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlim</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span><span class="mf">1.0</span><span class="p">])</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylim</span><span class="p">([</span><span class="mf">0.0</span><span class="p">,</span><span class="mf">1.05</span><span class="p">])</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">'False positive rate (1-specificity)'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">'True positive rate (recall)'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s">'lower right'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>

<span class="k">print</span><span class="p">(</span><span class="s">"Using a threshold of %.3f "</span> <span class="o">%</span> <span class="n">thr</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">+</span> <span class="s">"guarantees a sensitivity of %.3f "</span> <span class="o">%</span> <span class="n">tpr</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">+</span>  
      <span class="s">"and a specificity of %.3f"</span> <span class="o">%</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">fpr</span><span class="p">[</span><span class="n">idx</span><span class="p">])</span> <span class="o">+</span> 
      <span class="s">", i.e. a false positive rate of %.2f%%."</span> <span class="o">%</span> <span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">fpr</span><span class="p">[</span><span class="n">idx</span><span class="p">])</span><span class="o">*</span><span class="mi">100</span><span class="p">))</span>
</code></pre></div></div>

<h2 id="improvements">Improvements</h2>
<p>Some of the merchant IDs were repeated within the data so, rather than excluding them, I could have used them as extra columns. I also did not use all the statistical packages I imported and there was more analysis that could have been done on the resulting model.</p>

<p>You can see the full code <a href="https://github.com/SamMatt87/Data-science-sample-projects/blob/master/CC%20Fraud/fraud.py">here</a></p>


      <footer class="site-footer">
        
          <span class="site-footer-owner"><a href="https://github.com/SamMatt87/SamMatt87.github.io">SamMatt87.github.io</a> is maintained by <a href="https://github.com/SamMatt87">SamMatt87</a>.</span>
        
        <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com">GitHub Pages</a>.</span>
      </footer>
    </main>
  </body>
</html>
